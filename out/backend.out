24/01/02 16:31:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/opt/bitnami/python/lib/python3.6/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
24/01/02 16:32:00 INFO SparkContext: Running Spark version 2.4.3
24/01/02 16:32:00 INFO SparkContext: Submitted application: prediction
24/01/02 16:32:00 INFO SecurityManager: Changing view acls to: root
24/01/02 16:32:00 INFO SecurityManager: Changing modify acls to: root
24/01/02 16:32:00 INFO SecurityManager: Changing view acls groups to: 
24/01/02 16:32:00 INFO SecurityManager: Changing modify acls groups to: 
24/01/02 16:32:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
24/01/02 16:32:02 INFO Utils: Successfully started service 'sparkDriver' on port 41995.
24/01/02 16:32:02 INFO SparkEnv: Registering MapOutputTracker
24/01/02 16:32:02 INFO SparkEnv: Registering BlockManagerMaster
24/01/02 16:32:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/01/02 16:32:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/01/02 16:32:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-541d99f0-fc8f-49a1-95c3-e546774d7215
24/01/02 16:32:03 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
24/01/02 16:32:03 INFO SparkEnv: Registering OutputCommitCoordinator
24/01/02 16:32:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/01/02 16:32:06 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://3d5dfac46d74:4040
24/01/02 16:32:06 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
24/01/02 16:32:06 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.12:7077 after 99 ms (0 ms spent in bootstraps)
24/01/02 16:32:11 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240102163211-0000
24/01/02 16:32:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43933.
24/01/02 16:32:11 INFO NettyBlockTransferService: Server created on 3d5dfac46d74:43933
24/01/02 16:32:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/01/02 16:32:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240102163211-0000/0 on worker-20240102162721-172.19.0.7-44457 (172.19.0.7:44457) with 1 core(s)
24/01/02 16:32:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20240102163211-0000/0 on hostPort 172.19.0.7:44457 with 1 core(s), 1024.0 MB RAM
24/01/02 16:32:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240102163211-0000/1 on worker-20240102162721-172.19.0.5-35737 (172.19.0.5:35737) with 1 core(s)
24/01/02 16:32:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20240102163211-0000/1 on hostPort 172.19.0.5:35737 with 1 core(s), 1024.0 MB RAM
24/01/02 16:32:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 3d5dfac46d74, 43933, None)
24/01/02 16:32:11 INFO BlockManagerMasterEndpoint: Registering block manager 3d5dfac46d74:43933 with 366.3 MB RAM, BlockManagerId(driver, 3d5dfac46d74, 43933, None)
24/01/02 16:32:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 3d5dfac46d74, 43933, None)
24/01/02 16:32:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 3d5dfac46d74, 43933, None)
24/01/02 16:32:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240102163211-0000/0 is now RUNNING
24/01/02 16:32:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240102163211-0000/1 is now RUNNING
24/01/02 16:32:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
24/01/02 16:32:15 INFO SharedState: loading hive config file: file:/opt/bitnami/spark/conf/hive-site.xml
24/01/02 16:32:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/bitnami/spark/spark-warehouse').
24/01/02 16:32:15 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
24/01/02 16:32:21 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
INFO:     Started server process [275]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8066 (Press CTRL+C to quit)
24/01/02 16:32:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.5:39544) with ID 1
24/01/02 16:32:42 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.7:54952) with ID 0
24/01/02 16:32:50 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.7:38935 with 366.3 MB RAM, BlockManagerId(0, 172.19.0.7, 38935, None)
24/01/02 16:32:50 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.5:40039 with 366.3 MB RAM, BlockManagerId(1, 172.19.0.5, 40039, None)
24/01/02 16:36:38 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
24/01/02 16:36:46 INFO metastore: Trying to connect to metastore with URI thrift://hive-metastore:9083
24/01/02 16:36:48 INFO metastore: Connected to metastore.
24/01/02 16:36:49 INFO SessionState: Created local directory: /tmp/6960be52-c2a8-4d03-9416-01b62ff65c6b_resources
24/01/02 16:36:49 INFO SessionState: Created HDFS directory: /tmp/hive/root/6960be52-c2a8-4d03-9416-01b62ff65c6b
24/01/02 16:36:49 INFO SessionState: Created local directory: /tmp/root/6960be52-c2a8-4d03-9416-01b62ff65c6b
24/01/02 16:36:49 INFO SessionState: Created HDFS directory: /tmp/hive/root/6960be52-c2a8-4d03-9416-01b62ff65c6b/_tmp_space.db
24/01/02 16:36:49 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/opt/bitnami/spark/spark-warehouse
INFO:     127.0.0.1:40136 - "GET /company_scores HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling o30.sql.
: org.apache.spark.sql.catalyst.analysis.NoSuchDatabaseException: Database 'bigdata' not found;
	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.org$apache$spark$sql$catalyst$catalog$SessionCatalog$$requireDbExists(SessionCatalog.scala:178)
	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:265)
	at org.apache.spark.sql.execution.command.SetDatabaseCommand.run(databases.scala:59)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)
	at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:194)
	at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:194)
	at org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:194)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:79)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/python/lib/python3.6/site-packages/uvicorn/protocols/http/h11_impl.py", line 373, in run_asgi
    result = await app(self.scope, self.receive, self.send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/uvicorn/middleware/proxy_headers.py", line 75, in __call__
    return await self.app(scope, receive, send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/fastapi/applications.py", line 269, in __call__
    await super().__call__(scope, receive, send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/applications.py", line 124, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/middleware/errors.py", line 184, in __call__
    raise exc
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/middleware/errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/middleware/cors.py", line 84, in __call__
    await self.app(scope, receive, send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/exceptions.py", line 93, in __call__
    raise exc
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/exceptions.py", line 82, in __call__
    await self.app(scope, receive, sender)
  File "/opt/bitnami/python/lib/python3.6/site-packages/fastapi/middleware/asyncexitstack.py", line 21, in __call__
    raise e
  File "/opt/bitnami/python/lib/python3.6/site-packages/fastapi/middleware/asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/routing.py", line 670, in __call__
    await route.handle(scope, receive, send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/routing.py", line 266, in handle
    await self.app(scope, receive, send)
  File "/opt/bitnami/python/lib/python3.6/site-packages/starlette/routing.py", line 65, in app
    response = await func(request)
  File "/opt/bitnami/python/lib/python3.6/site-packages/fastapi/routing.py", line 232, in app
    dependant=dependant, values=values, is_coroutine=is_coroutine
  File "/opt/bitnami/python/lib/python3.6/site-packages/fastapi/routing.py", line 160, in run_endpoint_function
    return await dependant.call(**values)
  File "/python/backend/integration_app.py", line 70, in get_company_scores
    spark.sql("USE bigdata")
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 767, in sql
    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 71, in deco
    raise AnalysisException(s.split(': ', 1)[1], stackTrace)
pyspark.sql.utils.AnalysisException: "Database 'bigdata' not found;"
24/01/02 16:37:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 240.8 KB, free 366.1 MB)
24/01/02 16:37:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.4 KB, free 366.0 MB)
24/01/02 16:37:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 3d5dfac46d74:43933 (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:37:39 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
24/01/02 16:37:51 INFO FileInputFormat: Total input paths to process : 1
24/01/02 16:37:52 INFO SparkContext: Starting job: runJob at PythonRDD.scala:153
24/01/02 16:37:54 INFO DAGScheduler: Got job 0 (runJob at PythonRDD.scala:153) with 1 output partitions
24/01/02 16:37:54 INFO DAGScheduler: Final stage: ResultStage 0 (runJob at PythonRDD.scala:153)
24/01/02 16:37:54 INFO DAGScheduler: Parents of final stage: List()
24/01/02 16:37:54 INFO DAGScheduler: Missing parents: List()
24/01/02 16:37:54 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at RDD at PythonRDD.scala:53), which has no missing parents
24/01/02 16:37:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.0 KB, free 366.0 MB)
24/01/02 16:37:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 366.0 MB)
24/01/02 16:37:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 3d5dfac46d74:43933 (size: 3.8 KB, free: 366.3 MB)
24/01/02 16:37:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
24/01/02 16:37:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (PythonRDD[2] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
24/01/02 16:37:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
24/01/02 16:37:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 172.19.0.5, executor 1, partition 0, ANY, 7921 bytes)
24/01/02 16:37:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.19.0.5:40039 (size: 3.8 KB, free: 366.3 MB)
24/01/02 16:37:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.19.0.5:40039 (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 17887 ms on 172.19.0.5 (executor 1) (1/1)
24/01/02 16:38:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/01/02 16:38:13 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 33123
24/01/02 16:38:13 INFO DAGScheduler: ResultStage 0 (runJob at PythonRDD.scala:153) finished in 18.743 s
24/01/02 16:38:14 INFO DAGScheduler: Job 0 finished: runJob at PythonRDD.scala:153, took 21.115680 s
24/01/02 16:38:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 240.8 KB, free 365.8 MB)
24/01/02 16:38:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.4 KB, free 365.8 MB)
24/01/02 16:38:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 3d5dfac46d74:43933 (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:15 INFO SparkContext: Created broadcast 2 from textFile at ReadWrite.scala:615
24/01/02 16:38:15 INFO FileInputFormat: Total input paths to process : 1
24/01/02 16:38:15 INFO SparkContext: Starting job: first at ReadWrite.scala:615
24/01/02 16:38:15 INFO DAGScheduler: Got job 1 (first at ReadWrite.scala:615) with 1 output partitions
24/01/02 16:38:15 INFO DAGScheduler: Final stage: ResultStage 1 (first at ReadWrite.scala:615)
24/01/02 16:38:15 INFO DAGScheduler: Parents of final stage: List()
24/01/02 16:38:15 INFO DAGScheduler: Missing parents: List()
24/01/02 16:38:15 INFO DAGScheduler: Submitting ResultStage 1 (hdfs://namenode:9000/model/regression/metadata MapPartitionsRDD[4] at textFile at ReadWrite.scala:615), which has no missing parents
24/01/02 16:38:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 365.8 MB)
24/01/02 16:38:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 365.8 MB)
24/01/02 16:38:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 3d5dfac46d74:43933 (size: 2.1 KB, free: 366.2 MB)
24/01/02 16:38:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
24/01/02 16:38:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (hdfs://namenode:9000/model/regression/metadata MapPartitionsRDD[4] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
24/01/02 16:38:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
24/01/02 16:38:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 172.19.0.7, executor 0, partition 0, ANY, 7921 bytes)
24/01/02 16:38:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.19.0.7:38935 (size: 2.1 KB, free: 366.3 MB)
24/01/02 16:38:16 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.19.0.7:38935 (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 5076 ms on 172.19.0.7 (executor 0) (1/1)
24/01/02 16:38:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/01/02 16:38:20 INFO DAGScheduler: ResultStage 1 (first at ReadWrite.scala:615) finished in 5.131 s
24/01/02 16:38:20 INFO DAGScheduler: Job 1 finished: first at ReadWrite.scala:615, took 5.134113 s
24/01/02 16:38:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 240.8 KB, free 365.5 MB)
24/01/02 16:38:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.4 KB, free 365.5 MB)
24/01/02 16:38:21 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 3d5dfac46d74:43933 (size: 23.4 KB, free: 366.2 MB)
24/01/02 16:38:21 INFO SparkContext: Created broadcast 4 from textFile at ReadWrite.scala:615
24/01/02 16:38:21 INFO FileInputFormat: Total input paths to process : 1
24/01/02 16:38:21 INFO SparkContext: Starting job: first at ReadWrite.scala:615
24/01/02 16:38:21 INFO DAGScheduler: Got job 2 (first at ReadWrite.scala:615) with 1 output partitions
24/01/02 16:38:21 INFO DAGScheduler: Final stage: ResultStage 2 (first at ReadWrite.scala:615)
24/01/02 16:38:21 INFO DAGScheduler: Parents of final stage: List()
24/01/02 16:38:21 INFO DAGScheduler: Missing parents: List()
24/01/02 16:38:21 INFO DAGScheduler: Submitting ResultStage 2 (hdfs://namenode:9000/model/regression/stages/0_StringIndexer_69d5712b5f5d/metadata MapPartitionsRDD[6] at textFile at ReadWrite.scala:615), which has no missing parents
24/01/02 16:38:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 365.5 MB)
24/01/02 16:38:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.1 KB, free 365.5 MB)
24/01/02 16:38:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 3d5dfac46d74:43933 (size: 2.1 KB, free: 366.2 MB)
24/01/02 16:38:21 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
24/01/02 16:38:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (hdfs://namenode:9000/model/regression/stages/0_StringIndexer_69d5712b5f5d/metadata MapPartitionsRDD[6] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
24/01/02 16:38:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
24/01/02 16:38:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 172.19.0.7, executor 0, partition 0, ANY, 7957 bytes)
24/01/02 16:38:21 INFO ContextCleaner: Cleaned accumulator 34
24/01/02 16:38:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 3d5dfac46d74:43933 in memory (size: 2.1 KB, free: 366.2 MB)
24/01/02 16:38:22 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.19.0.7:38935 in memory (size: 2.1 KB, free: 366.3 MB)
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 50
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 17
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 37
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 49
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 10
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 8
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 24
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 48
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 25
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 19
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 46
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 13
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 31
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 20
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 6
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 32
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 35
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 43
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 7
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 18
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 12
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 33
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 42
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 26
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 3
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 5
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 4
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 47
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 16
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 1
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 14
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 2
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 22
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 27
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 44
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 21
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 11
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 45
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 41
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 23
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 15
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 28
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 30
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 39
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 9
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 38
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 36
24/01/02 16:38:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 3d5dfac46d74:43933 in memory (size: 3.8 KB, free: 366.2 MB)
24/01/02 16:38:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.19.0.5:40039 in memory (size: 3.8 KB, free: 366.3 MB)
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 29
24/01/02 16:38:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 3d5dfac46d74:43933 in memory (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.19.0.7:38935 (size: 2.1 KB, free: 366.3 MB)
24/01/02 16:38:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.19.0.7:38935 in memory (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:22 INFO ContextCleaner: Cleaned accumulator 40
24/01/02 16:38:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.19.0.7:38935 (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1471 ms on 172.19.0.7 (executor 0) (1/1)
24/01/02 16:38:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/01/02 16:38:23 INFO DAGScheduler: ResultStage 2 (first at ReadWrite.scala:615) finished in 1.561 s
24/01/02 16:38:23 INFO DAGScheduler: Job 2 finished: first at ReadWrite.scala:615, took 1.568326 s
24/01/02 16:38:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 240.8 KB, free 365.5 MB)
24/01/02 16:38:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.4 KB, free 365.5 MB)
24/01/02 16:38:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 3d5dfac46d74:43933 (size: 23.4 KB, free: 366.2 MB)
24/01/02 16:38:23 INFO SparkContext: Created broadcast 6 from textFile at ReadWrite.scala:615
24/01/02 16:38:23 INFO FileInputFormat: Total input paths to process : 1
24/01/02 16:38:23 INFO SparkContext: Starting job: first at ReadWrite.scala:615
24/01/02 16:38:23 INFO DAGScheduler: Got job 3 (first at ReadWrite.scala:615) with 1 output partitions
24/01/02 16:38:23 INFO DAGScheduler: Final stage: ResultStage 3 (first at ReadWrite.scala:615)
24/01/02 16:38:23 INFO DAGScheduler: Parents of final stage: List()
24/01/02 16:38:23 INFO DAGScheduler: Missing parents: List()
24/01/02 16:38:23 INFO DAGScheduler: Submitting ResultStage 3 (hdfs://namenode:9000/model/regression/stages/0_StringIndexer_69d5712b5f5d/metadata MapPartitionsRDD[8] at textFile at ReadWrite.scala:615), which has no missing parents
24/01/02 16:38:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 3.5 KB, free 365.5 MB)
24/01/02 16:38:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.1 KB, free 365.5 MB)
24/01/02 16:38:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 3d5dfac46d74:43933 (size: 2.1 KB, free: 366.2 MB)
24/01/02 16:38:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
24/01/02 16:38:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (hdfs://namenode:9000/model/regression/stages/0_StringIndexer_69d5712b5f5d/metadata MapPartitionsRDD[8] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
24/01/02 16:38:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
24/01/02 16:38:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 172.19.0.7, executor 0, partition 0, ANY, 7957 bytes)
24/01/02 16:38:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.19.0.7:38935 (size: 2.1 KB, free: 366.3 MB)
24/01/02 16:38:24 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.19.0.7:38935 (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:25 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1081 ms on 172.19.0.7 (executor 0) (1/1)
24/01/02 16:38:25 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/01/02 16:38:25 INFO DAGScheduler: ResultStage 3 (first at ReadWrite.scala:615) finished in 1.249 s
24/01/02 16:38:25 INFO DAGScheduler: Job 3 finished: first at ReadWrite.scala:615, took 1.252800 s
24/01/02 16:38:32 INFO SparkContext: Starting job: parquet at StringIndexer.scala:313
24/01/02 16:38:32 INFO DAGScheduler: Got job 4 (parquet at StringIndexer.scala:313) with 1 output partitions
24/01/02 16:38:32 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at StringIndexer.scala:313)
24/01/02 16:38:32 INFO DAGScheduler: Parents of final stage: List()
24/01/02 16:38:32 INFO DAGScheduler: Missing parents: List()
24/01/02 16:38:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[10] at parquet at StringIndexer.scala:313), which has no missing parents
24/01/02 16:38:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 71.1 KB, free 365.4 MB)
24/01/02 16:38:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 25.5 KB, free 365.4 MB)
24/01/02 16:38:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 3d5dfac46d74:43933 (size: 25.5 KB, free: 366.2 MB)
24/01/02 16:38:32 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
24/01/02 16:38:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at parquet at StringIndexer.scala:313) (first 15 tasks are for partitions Vector(0))
24/01/02 16:38:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
24/01/02 16:38:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 172.19.0.7, executor 0, partition 0, PROCESS_LOCAL, 8117 bytes)
24/01/02 16:38:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.19.0.7:38935 (size: 25.5 KB, free: 366.2 MB)
24/01/02 16:38:44 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 12184 ms on 172.19.0.7 (executor 0) (1/1)
24/01/02 16:38:44 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/01/02 16:38:44 INFO DAGScheduler: ResultStage 4 (parquet at StringIndexer.scala:313) finished in 12.380 s
24/01/02 16:38:44 INFO DAGScheduler: Job 4 finished: parquet at StringIndexer.scala:313, took 12.383127 s
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 74
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 101
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 121
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 76
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 82
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 113
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 125
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 63
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 84
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 60
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 87
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 100
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 108
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 86
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 98
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 80
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 109
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 92
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 79
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 124
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 105
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 56
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 95
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 90
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 85
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 58
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 71
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 117
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 75
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 3d5dfac46d74:43933 in memory (size: 2.1 KB, free: 366.2 MB)
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.19.0.7:38935 in memory (size: 2.1 KB, free: 366.2 MB)
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 96
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 104
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 110
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 118
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 93
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 67
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 51
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 65
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 72
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 112
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 3d5dfac46d74:43933 in memory (size: 25.5 KB, free: 366.2 MB)
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.19.0.7:38935 in memory (size: 25.5 KB, free: 366.3 MB)
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 106
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 111
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 102
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 64
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 88
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 89
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 97
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 103
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 53
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 70
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 3d5dfac46d74:43933 in memory (size: 2.1 KB, free: 366.2 MB)
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.19.0.7:38935 in memory (size: 2.1 KB, free: 366.3 MB)
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 123
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 78
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 3d5dfac46d74:43933 in memory (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.19.0.7:38935 in memory (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 61
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 62
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 107
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 55
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 115
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 81
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 119
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 3d5dfac46d74:43933 in memory (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:45 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.19.0.7:38935 in memory (size: 23.4 KB, free: 366.3 MB)
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 59
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 77
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 120
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 94
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 116
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 52
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 68
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 73
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 122
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 57
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 54
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 83
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 91
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 99
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 69
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 114
24/01/02 16:38:45 INFO ContextCleaner: Cleaned accumulator 66
24/01/02 16:38:48 INFO FileSourceStrategy: Pruning directories with: 
24/01/02 16:38:48 INFO FileSourceStrategy: Post-Scan Filters: 
24/01/02 16:38:48 INFO FileSourceStrategy: Output Data Schema: struct<labels: array<string>>
24/01/02 16:38:49 INFO FileSourceScanExec: Pushed Filters: 
24/01/02 16:38:56 INFO CodeGenerator: Code generated in 1874.863135 ms
24/01/02 16:38:58 INFO CodeGenerator: Code generated in 29.80576 ms
24/01/02 16:38:58 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 283.2 KB, free 365.8 MB)
24/01/02 16:38:59 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.5 KB, free 365.7 MB)
24/01/02 16:38:59 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 3d5dfac46d74:43933 (size: 24.5 KB, free: 366.3 MB)
24/01/02 16:38:59 INFO SparkContext: Created broadcast 9 from head at StringIndexer.scala:315
24/01/02 16:38:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/01/02 16:39:02 INFO SparkContext: Starting job: head at StringIndexer.scala:315
24/01/02 16:39:02 INFO DAGScheduler: Got job 5 (head at StringIndexer.scala:315) with 1 output partitions
24/01/02 16:39:02 INFO DAGScheduler: Final stage: ResultStage 5 (head at StringIndexer.scala:315)
24/01/02 16:39:02 INFO DAGScheduler: Parents of final stage: List()
24/01/02 16:39:02 INFO DAGScheduler: Missing parents: List()
24/01/02 16:39:02 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[14] at head at StringIndexer.scala:315), which has no missing parents
24/01/02 16:39:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 8.9 KB, free 365.7 MB)
24/01/02 16:39:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.5 KB, free 365.7 MB)
24/01/02 16:39:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 3d5dfac46d74:43933 (size: 4.5 KB, free: 366.2 MB)
24/01/02 16:39:03 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
24/01/02 16:39:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[14] at head at StringIndexer.scala:315) (first 15 tasks are for partitions Vector(0))
24/01/02 16:39:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
24/01/02 16:39:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, 172.19.0.5, executor 1, partition 0, ANY, 8428 bytes)
24/01/02 16:39:04 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.19.0.5:40039 (size: 4.5 KB, free: 366.3 MB)
24/01/02 16:39:12 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.19.0.5:40039 (size: 24.5 KB, free: 366.2 MB)
